{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonpickle in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpickle) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->jsonpickle) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai mengunduh maksimum 6000 tweets\n",
      "Jumlah Tweets telah tersimpan: 139\n",
      "Tidak ada lagi Tweet ditemukan dengan Query=\"ekonomi psbb\"\n",
      "\n",
      "Selesai! 139 tweets tersimpan di \"ekonomi_psbb.json\"\n"
     ]
    }
   ],
   "source": [
    "#Import library yang dibutuhkan dalam proses pengambilan data\n",
    "import tweepy,sys,jsonpickle\n",
    "\"\"\"\n",
    "=> Tweepy merupakan bagian package Python yang berfungsi untuk melakukan interaksi dengan API yang telah disediakan \n",
    "oleh twitter dengan mudah dalam pengambilan data. Tweepy disini nantinya akan digunakan untuk proses authentication API twitter.\n",
    "=> jsonpickle digunakan untuk serialisasi dan deserialisasi objek Python kompleks ke dan dari JSON yang dimana dapat \n",
    "mengambil hampir semua objek Python dan mengubah objek tersebut menjadi JSON. Selain itu, dapat menyusun kembali objek tersebut\n",
    "kembali ke Python. jsonpickle memungkinkan struktur data yang lebih kompleks untuk diserialkan ke JSON.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Agar python dan twitter terhubung dengan baik, terlebih dahulu harus mendapatkan authentication berupa akses token untuk\n",
    "berinteraksi dengan Twitter API. Hal ini dilakukan agar bisa mengekstrak data dari Twitter.\n",
    "\"\"\"\n",
    "consumer_key = '*****' #di isi API key dari akun developer twitter\n",
    "consumer_secret = '*****' #di isi API secret dari akun developer twitter\n",
    "access_token = '*****'\n",
    "access_secret = '*****'\n",
    "\n",
    "qry='ekonomi psbb'#Kata kunci yang ingin dicari\n",
    "maxTweets =  6000 #Jumlah maksimum tweet yang ingin kita ambil. Isi sembarang nilai sesuai kebutuhan\n",
    "tweetsPerQry = 100  #Jumlah hasil yang diambil per Request. Jangan isi lebih dari 100, tidak diperbolehkan oleh Twitter\n",
    "fName='ekonomi_psbb.json' #Nama file hasil Crawling untuk proses penyimpanan data\n",
    "\n",
    "#Melakukan proses authentication API twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "#Ada dua parameter selain authentikasi, wait_on_rate_limit, dan wait_on_rate_limit_notify \n",
    "#Digunakan untuk memanggil fungsi tidur otomatis di Tweepy ketika mencapai batas tingkat API Twitter.\n",
    "\n",
    "#auth = tweepy.API(auth, proxy='https://your_proxy.server:port)'\n",
    "\n",
    "if (not api):\n",
    "    sys.exit('Autentikasi gagal, mohon cek \"Consumer Key\" & \"Consumer Secret\" Twitter anda')\n",
    "\n",
    "sinceId, max_id, tweetCount = None, -1, 0\n",
    "\n",
    "print(\"Mulai mengunduh maksimum {0} tweets\".format(maxTweets))\n",
    "with open(fName,'w') as f:\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=qry, tweet_mode=\"extended\", count=tweetsPerQry, result_type=\"recent\")\n",
    "                else:\n",
    "                    new_tweets = api.search(q=qry, tweet_mode=\"extended\", count=tweetsPerQry, result_type=\"recent\", \n",
    "                                            since_id=sinceId)\n",
    "                    \n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=qry, tweet_mode=\"extended\", count=tweetsPerQry, result_type=\"recent\", \n",
    "                                            max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.search(q=qry, tweet_mode=\"extended\", count=tweetsPerQry, result_type=\"recent\", \n",
    "                                            max_id=str(max_id - 1),since_id=sinceId)\n",
    "            \n",
    "            \"\"\"Penggunakan while loop untuk meminta semua tweet yang tersedia di qry kata kunci yang diinginkan. \n",
    "            Jika Statements pada Baris diatas digunakan untuk meminta data tweet, ketika max_id kurang dari 1, \n",
    "            program menjalankan query pencarian dari tweet terbaru dan kemudian menyimpan id terakhir ke max_id sehingga\n",
    "            program dapat membuat permintaan lagi dari tweet terlama berdasarkan max_id.\n",
    "            \"\"\"      \n",
    "            if not new_tweets:\n",
    "                print('\\nTidak ada lagi Tweet ditemukan dengan Query=\"{0}\"'.format(qry));break\n",
    "            for tweet in new_tweets:\n",
    "                f.write(jsonpickle.encode(tweet._json,unpicklable=False)+'\\n')\n",
    "            tweetCount+=len(new_tweets)\n",
    "            sys.stdout.write(\"\\r\");sys.stdout.write(\"Jumlah Tweets telah tersimpan: %.0f\" %tweetCount);sys.stdout.flush()\n",
    "            max_id=new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"some error : \" + str(e));break # Aya error, keluar\n",
    "print ('\\nSelesai! {0} tweets tersimpan di \"{1}\"'.format(tweetCount,fName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "#Untuk membuka file JSON kemudian dibaca secara perbaris\n",
    "for line in open('C:/Users/Niken Amelia/project_jupyter/TA/PSBB - EKONOMI/crawling/data/json baru (sdg diolah)/json (sdg diolah)/gabungan.json', 'r'):\n",
    "    data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Ubah bentuk JSON ke dalam dataframe, agar memudahkan perubahan format ke CSV\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "#Tampilkan dataframe yang sudah dibuat\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleksi atribut mana didalam dataframe yang nantinya ingin disimpan ke dalam bentuk CSV\n",
    "saved_column = df[['full_text']]#you can also use df['column_name']\n",
    "\n",
    "#Tampilkan atribut dari hasil seleksi sebelumnya\n",
    "saved_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simpan atribut tersebut ke dalam bentuk format CSV tanpa judul dan index\n",
    "saved_column.to_csv('C:/Users/Niken Amelia/project_jupyter/TA/PSBB - EKONOMI/crawling/data/json baru (sdg diolah)/json (sdg diolah)/gabungan.csv', header=None, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
